{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MICQP Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- first by introducing trajectory optimisation, \n",
    "- then providing a MIQCP encoding of the problem, \n",
    "- then briefly reviewing methods for solving convex programs, and \n",
    "- finally solving the MIQCP encoding of a trajectory optimisation problem with a provided solver. \n",
    "    - We will provide you with examples code calling a MIQCP solver after you have submitted the skeleton notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulating the Problem as MIQCP\n",
    "\n",
    "In our simplified real world problem of a vehicle planning its trajectory through space, our **constraints** include all of the following:\n",
    "\n",
    "- a maximum speed on the vehicle\n",
    "- fixed start and end locations\n",
    "- a need to avoid static objects\n",
    "\n",
    "While taking these into account, our **objective function** could look to minimize: *fuel used, travel time, a combination of the two, or even a range of other functions*. We will choose to focus on **?????** for our problem.\n",
    "\n",
    "Because of the need to avoid objects, our problem formulation requires the use of **mixed integers** to maintain the convexity of the problem space. We will start with a brief overview of convexity for completeness.\n",
    "\n",
    "### Convexity\n",
    "\n",
    "A convex set is defined as a set where for any two points (X, Y) within the set, the line that connects those points will also lie within the set. More formally, if X is a convex set and $ x_1...x_n $ are points in the set, then:\n",
    "\n",
    "\\begin{equation*}\n",
    "x = \\sum_{k=1}^n x_k\\lambda_k  \\text{ where } \\lambda_k > 0 \\text{ and }  \\sum_{k=1}^n \\lambda_k = 1\n",
    "\\end{equation*}\n",
    "\n",
    "[Source](https://en.wikibooks.org/wiki/Convexity/What_is_a_convex_set%3F)\n",
    "\n",
    "Convexity has huge implications for optimization, and much work has been put into techniques for convex problems as well as techniques to restructure non-convex problems into convex ones. The image below gives good intuition for convexity of a set.\n",
    "\n",
    "<img src=\"diagonals.png\" style=\"width:50%;\"/>\n",
    "By <a href=\"//commons.wikimedia.org/wiki/User:Dbc334\" title=\"User:Dbc334\">Dbc334</a> - Drawn by me, Public Domain, <a href=\"https://commons.wikimedia.org/w/index.php?curid=1678436\">Link</a>\n",
    "\n",
    "\n",
    "### Convexity for Trajectory Planning\n",
    "\n",
    "Though the concept of convexity extends to n-dimensions, we will focus on convexity of a 2D space for navigation. It can be simply seen that the introduction of an obstacle into a convex area including the vehicle and its destination, will cause the area to become non-convex. \n",
    "\n",
    "We work around this non-convexity by formulating the problem as a mixed integer program, with binary variables that vary depending on the region the vehicle is in at time *k*. These variables allow for all constraints to be flexibly satisfied **without having to address the combinatoric nature of the \"or\" formulation??????**.\n",
    "\n",
    "**Note**: to retain the MIQCP form of the problem, the space around the obstacle to be avoided must be convex, meaning that if the obstacle is non-convex it must be approximated by a larger convex space.\n",
    "\n",
    "The resulting mixed integer constraints can be first thought of as:\n",
    "\\begin{equation*}\n",
    "x_i \\leq x_{min} \\\\\n",
    "\\text{or } x_i \\geq x_{min} \\\\\n",
    "\\text{or } y_i \\leq y_{min} \\\\\n",
    "\\text{or } y_i \\geq y_{min} \\\\\n",
    "\\end{equation*}\n",
    "\n",
    "Which can then be reformulated as mixed integer constraints:\n",
    "\n",
    "\\begin{equation*}\n",
    "x_i \\leq x_{min} + Ma_1 \\\\\n",
    "\\text{and } x_i \\geq x_{min} + Ma_2 \\\\\n",
    "\\text{and } y_i \\leq y_{min} + Ma_3 \\\\\n",
    "\\text{and } y_i \\geq y_{min} + Ma_4 \\\\\n",
    "\\end{equation*}\n",
    "\n",
    "<img src=\"environment.png\" style=\"width:50%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Convex Optimization Problems\n",
    "\n",
    "Now that we've spent the time to understand convex spaces, it is time to discuss how to use this *magical* property called convexity to reach optimal solutions. As we've discussed, convexity is an important property that generally allows us to guarantee that we can find an optimal solution. \n",
    "\n",
    "Beyond living in a convex space, the other requirement of a convex optimization problem is that the actual **function** being optimized is also **convex**. A convex function can be formally defined as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{for any x,y for which the function, f(*), exists and 0 $\\leq$ a $\\leq$ 1} \\\\\n",
    "f(ax + (1-a)y) \\leq af(x)+(1-a)f(y) \\\\\n",
    "\\end{equation*}\n",
    "\n",
    "This can be easily visualized in the below diagram:\n",
    "\n",
    "<img src=\"convexfunction.png\" style=\"width:50%;\"/>\n",
    "\n",
    "\n",
    "By <a href=\"//commons.wikimedia.org/w/index.php?title=User:Eli_Osherovich&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"User:Eli Osherovich (page does not exist)\">Eli Osherovich</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/3.0\" title=\"Creative Commons Attribution-Share Alike 3.0\">CC BY-SA 3.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=10764763\">Link</a>\n",
    "\n",
    "These two requirements, both a convex set and function, enforce the rule that **any local minima is also a global minima**. That's correct, please read that again. **Local minima = Global Minima**\n",
    "\n",
    "Without further information, here is a primer on some common convex optimization approaches\n",
    "\n",
    "## Gradient Methods\n",
    "\n",
    "This technique does what any intelligent person would do when trying to find a minima: follow a path leading down. A gradient based method **requires???** the following parts:\n",
    "\n",
    "1) A way to obtain a gradient of the function\n",
    "2) A way to determine a \"step size\" in the direction of this gradient\n",
    "3) Stopping criterion to determine if the solution is \"close enough\" to a minima\n",
    "\n",
    "Gradient descent - calculates gradient of function  \n",
    "Steepest descent - 1st order Taylor approximation of local gradient  \n",
    "Newton's Method  - Minimizer of 2nd order Taylor approximation  (Linear equality constrained problem w/ twice diff. objective function into linear equality quadratic problem)\n",
    "\n",
    "1) Randomly sample a point in space, x  \n",
    "2) Calculate or approximate the local gradient of the function  \n",
    "3) Move the point, x, a small amount in the steepest negative direction  \n",
    "4) Repeat steps 2,3 until the point x has been determined to be in a minima  \n",
    "\n",
    "**Note**: more sophisticated variants often vary the step size from step 3 based upon factors such as the steepness of the gradient. Also, there is no one correct answer to guessing whether a x has reached a minima. \n",
    "\n",
    "## Interior Point Methods (IPM)\n",
    "\n",
    "Interior point methods take an optimization problem with linear equality and inequality constraints and reshape into linear equality constrained problems\n",
    "\n",
    "### Barrier Method \n",
    "\n",
    "The Barrier Method is a form of IPM in which general inequality constraints are made implicit by moving them into the objective function. \n",
    "\n",
    "The value of the objective function is made to be infinite at any points which were previously outside of the feasible set as marked by the inequality constraints. This is done by use of an indicator function, $I(x)$. Formally speaking, this can be said as:\n",
    "\n",
    "$f(x)$ is the objective function  \n",
    "$f_0(x)$ is the original objective function  \n",
    "$I(u)$ is the indicator function  \n",
    "$f_i(x)$ represents the implicit inequalities  \n",
    "  \n",
    "\\begin{equation*}\n",
    "f(x) = f_0(x) + \\sum_{i=1}^mI(f_i(x))\\\\\n",
    "\\text{where: } I(u)=  \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      0 & u \\leq 0 \\\\\n",
    "      \\infty & u \\gt 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "\\end{equation*}\n",
    "\n",
    "While this formulation is elegant, it is **not differentiable** and does not lend itself to techniques such as Newton's Method. This inspired the use of a **logarithmic barrier** of the form:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{I}(u ) = -(1/t)log(-u)\\\\\n",
    "t \\gt 0\n",
    "\\end{equation*}\n",
    "\n",
    "This alternative indicator function maintains the convexity and differentiability of the problem while allowing for good approximation of the original barrier. \n",
    "\n",
    "**Note**: increasing the value of $t$ increases the accuracy of the approximation\n",
    "\n",
    "\n",
    "### Primal-Dual Method\n",
    "\n",
    "\n",
    "## Simplex Method\n",
    "\n",
    "**Note**: Dantzig's Simplex Method is only valid for **linear programs**, and does not generalize to the greater class of convex optimization problems. Regardless, it is briefly covered here for completeness.\n",
    "\n",
    "The simplex method leverages the inherent monotonicity of a linear program and bears the relatively strict requirements of an LP such as a linear objective function and a feasible set which can be represented as a convex polytope. \n",
    "\n",
    "Because the objective function is monotonic and the feasible set is defined by linear inequalities, it can be shown that if an optimal point exists it will be at one of the vertices of the convex polytope. As a result, the algorithm simply begins at one such vertex and follows the connected edge of the polytope which is most rapidly approaching an optimal solution of the objective function (the edge with the most negative gradient in the case of minimization). This behavior continues until the algorithm reaches the optimal point within the polytope.\n",
    "\n",
    "**Note**: in the case of a feasible set that is an open convex polytope it is possible for the optimal solution to not exist, as the simplex method may discover an unbounded edge. In this case, the solution is not feasible and further constraints must be imposed upon the feasible set to allow for a solution.\n",
    "\n",
    "The image below visualizes Dantzig's Simplex Method over a 3-dimensional convex polytope\n",
    "\n",
    "<img src=\"simplex.png\" style=\"width:50%;\"/>\n",
    "\n",
    "\n",
    "By <a href=\"//commons.wikimedia.org/wiki/User:Sdo\" title=\"User:Sdo\">User:Sdo</a> - Created using gimp based on <a href=\"//commons.wikimedia.org/wiki/File:Elongated_pentagonal_orthocupolarotunda.png\" title=\"File:Elongated pentagonal orthocupolarotunda.png\">Image:Elongated_pentagonal_orthocupolarotunda.png</a>., <a href=\"http://creativecommons.org/licenses/by-sa/3.0/\" title=\"Creative Commons Attribution-Share Alike 3.0\">CC BY-SA 3.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=1295511\">Link</a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
